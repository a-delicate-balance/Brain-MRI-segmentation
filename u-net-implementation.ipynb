{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from tensorflow.keras.layers import Input, concatenate, add\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not on TPU\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    print(\"on TPU\")\n",
    "except:\n",
    "    print(\"not on TPU\")\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (256,256)\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE_PER_REPLICA = 32\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MRI Dataset](https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation)\n",
    "I use \"LGG Segmentation Dataset\" \n",
    "Dataset contains brain MR images together with manual FLAIR abnormality segmentation masks.\n",
    "\n",
    "The images were obtained from The Cancer Imaging Archive (TCIA).\n",
    "\n",
    "They correspond to 110 patients(total 7858 image) included in The Cancer Genome Atlas (TCGA) lower-grade glioma collection with at least fluid-attenuated inversion recovery (FLAIR) sequence and genomic cluster data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = glob.glob('./lgg-mri-segmentation/kaggle_3m/*/*_mask.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc9ea5a50454382ac367fcae8fd4696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3929 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "empty_masks = []\n",
    "non_empty_masks = []\n",
    "\n",
    "for mask_path in tqdm(mask_paths):\n",
    "    mask = np.array(Image.open(mask_path))\n",
    "    if (mask == 0).all():\n",
    "        empty_masks.append(mask_path)\n",
    "    else:\n",
    "        non_empty_masks.append(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373\n",
      "2556\n"
     ]
    }
   ],
   "source": [
    "print(len(non_empty_masks))\n",
    "print(len(empty_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select all data with non empty mask and 200 with empty mask data for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = non_empty_masks + [empty_masks[idx] for idx in np.random.choice(len(empty_masks), 200)]\n",
    "np.random.shuffle(mask_paths)\n",
    "image_paths = [mask_path.replace('_mask', '') for mask_path in mask_paths]\n",
    "val_image_paths, val_mask_paths = image_paths[1300:], mask_paths[1300:]\n",
    "image_paths, mask_paths = image_paths[:1300], mask_paths[:1300]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7e4c7a538c4d8d91b194d0b7462bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "not_ = []\n",
    "for img_path in tqdm(image_paths):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tfio.experimental.image.decode_tiff(image)\n",
    "    if not (np.array(image)[:,:,3] == 255).all():\n",
    "        print(img_path)\n",
    "        not_.append(img_path)\n",
    "print(len(not_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader and augument data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_path, mask_path):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tfio.experimental.image.decode_tiff(image)\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tfio.experimental.image.decode_tiff(mask)\n",
    "    # tiff have 4 dimesions with last dimesion is empty so we only need fist 3 channels\n",
    "    return image[:,:,:3], mask[:,:,:1]\n",
    "\n",
    "def random_flip(image, mask):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    return image, mask\n",
    "\n",
    "def random_rotate(image, mask):\n",
    "    k = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k)\n",
    "    mask = tf.image.rot90(mask, k)\n",
    "    return image, mask\n",
    "\n",
    "def random_contrast(image, mask):\n",
    "    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "    return image, mask\n",
    "\n",
    "def normalize_image(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image,[*IMG_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    mask = tf.image.resize(mask,[*IMG_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = (image - 127.5) / 127.5\n",
    "    mask = (mask - 127.5) / 127.5\n",
    "    return image, mask\n",
    "\n",
    "def rescale_image(image, mask):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) # Rescale to [0, 1]\n",
    "    image = tf.image.resize(image,[*IMG_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
    "    mask = tf.image.resize(mask,[*IMG_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, mask\n",
    "\n",
    "@tf.function\n",
    "def create_train_dataset(image, mask, is_normalize = False, batch_size = 12, cache = False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image, mask))\n",
    "#     dataset = tf.data.TFRecordDataset(dataset)\n",
    "    options = tf.data.Options()\n",
    "    options.deterministic = False\n",
    "    dataset = dataset.with_options(options)\n",
    "    dataset = dataset.map(load_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(2) # Repeat before apply transform function is equal with data augument.\n",
    "    dataset = dataset.map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(random_rotate, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(random_contrast, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if is_normalize:\n",
    "        print('Dataset images will normalize to [-1, 1]')\n",
    "        dataset = dataset.map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    else:\n",
    "        print('Dataset images will rescale to [0, 1]')\n",
    "        dataset = dataset.map(rescale_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    if cache:\n",
    "        return dataset.cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    else:\n",
    "        return dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_image(img_path, mask_path):\n",
    "    image = tf.image.convert_image_dtype(img_path, tf.float32)\n",
    "    image = tf.image.resize(image,[*IMG_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    mask = tf.image.convert_image_dtype(mask_path, tf.float32)\n",
    "    mask = tf.image.resize(mask,[*IMG_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, mask\n",
    "\n",
    "def create_val_dataset(image, mask, batch_size = 1):\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((image, mask))\n",
    "    options = tf.data.Options()\n",
    "    options.deterministic = False\n",
    "    val_dataset = val_dataset.with_options(options)\n",
    "    val_dataset = val_dataset.map(load_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.map(val_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "    val_dataset = val_dataset.batch(val_batch_size, drop_remainder=True).cache().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset images will rescale to [0, 1]\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    dataset = create_train_dataset(image_paths, mask_paths, is_normalize = False, batch_size = GLOBAL_BATCH_SIZE, cache = True)\n",
    "    val_dataset = create_val_dataset(val_image_paths, val_mask_paths, batch_size = 1)\n",
    "    options = tf.distribute.InputOptions(experimental_fetch_to_device=False)\n",
    "    dataset = strategy.experimental_distribute_dataset(dataset, options)\n",
    "    val_dataset = strategy.experimental_distribute_dataset(val_dataset, options)\n",
    "    test_dataset = create_val_dataset(val_image_paths, val_mask_paths, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 22:15:41.829296: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: CANCELLED: GetNextFromShard was cancelled\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2024-09-25 22:15:41.848514: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataset))\n\u001b[0;32m----> 3\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m      4\u001b[0m mask \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      6\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m, figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[0;32m~/Projects/pec-stuff/data-sci/lib/python3.12/site-packages/tensorflow/python/framework/tensor.py:260\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    254\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    255\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    256\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# Check image\n",
    "sample = next(iter(dataset))\n",
    "img = sample[0].values\n",
    "mask = sample[1].values\n",
    "\n",
    "fig, ax = plt.subplots(4,6, figsize = (16,4*3))\n",
    "ax = ax.flatten()\n",
    "for i in range(4*3):\n",
    "    ax[2*i].imshow(img[0][i])\n",
    "    ax[2*i].set_yticks([])\n",
    "    ax[2*i+1].imshow(mask[0][i])\n",
    "    ax[2*i+1].set_yticks([])\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "fig.suptitle('Image/Mask', y = 0.91)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metric between the predicted segmentation and the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 1\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "    return total_loss\n",
    "\n",
    "tf.function\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "tf.function\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "@tf.function\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "@tf.function\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    jaccard_coef = (intersection + 1) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection + 1)\n",
    "    return jaccard_coef\n",
    "\n",
    "@tf.function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, filters, kernel_size=(3, 3), activation='relu', padding='same', kernel_initializer='he_normal', dropout=0.1):\n",
    "    conv = tf.keras.layers.Conv2D(filters, kernel_size, activation=activation, padding=padding, kernel_initializer=kernel_initializer)(inputs)\n",
    "    conv = tf.keras.layers.Dropout(dropout)(conv)\n",
    "    conv = tf.keras.layers.Conv2D(filters, kernel_size, activation=activation, padding=padding, kernel_initializer=kernel_initializer)(conv)\n",
    "    return conv\n",
    "\n",
    "def build_model():\n",
    "    inputs = tf.keras.layers.Input((*IMG_SIZE, CHANNELS))\n",
    "\n",
    "    # Contracting Path\n",
    "    c1 = conv_block(inputs, 16)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 32)\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 64, dropout = 0.2)\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 128, dropout = 0.2)\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = conv_block(p4, 256, dropout=0.3)\n",
    "\n",
    "    # Expansive Path\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    c6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = conv_block(c6, 128, dropout = 0.2)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    c7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = conv_block(c7, 64, dropout = 0.2)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    c8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = conv_block(c8, 32)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    c9 = tf.keras.layers.concatenate([u9, c1])\n",
    "    c9 = conv_block(c9, 16)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "with strategy.scope():\n",
    "    lr = 1e-3\n",
    "    # decay_rate = lr/EPOCHS\n",
    "\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "#                   loss='binary_crossentropy',\n",
    "                  loss=dice_loss,\n",
    "                  metrics=[tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "                         dice_coef, precision, sensitivity, specificity],\n",
    "#                  steps_per_execution = 10\n",
    "                 )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint('unet_model.keras',\n",
    "                                                      verbose=1,\n",
    "                                                      save_freq = 400)\n",
    "\n",
    "    callbacks = [checkpointer]\n",
    "EPOCHS = 30\n",
    "history = model.fit(dataset, validation_data=val_dataset, epochs=30, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('/kaggle/working/unet_model.keras')\n",
    "\n",
    "iter_val_dataset = iter(val_dataset)\n",
    "\n",
    "fig, ax = plt.subplots(8,2, figsize = (10,40))\n",
    "ax = ax.flatten()\n",
    "for i in range(4*2):\n",
    "    pair = next(iter_val_dataset)\n",
    "    img = pair[0].values\n",
    "    mask = pair[1].values\n",
    "    ax[2*i].imshow(model(img[0])[0])\n",
    "#     ax[2*i].set_yticks([])\n",
    "    ax[2*i+1].imshow(mask[0][0])\n",
    "    ax[2*i+1].set_yticks([])\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "fig.suptitle('Image/Mask', y = 0.89)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('/kaggle/working/unet_model.keras')\n",
    "a = 0\n",
    "for x in val_dataset:\n",
    "    a +=1\n",
    "    if a == 4:\n",
    "        break\n",
    "    image, mask = x[0], x[1]\n",
    "    print(image.shape)\n",
    "    pred = model(image)\n",
    "    plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(2, 2, i*2+1)\n",
    "        plt.imshow(pred[i] > 0.5)\n",
    "        plt.subplot(2, 2, i*2+2)\n",
    "        plt.imshow(mask[i])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 44321,
     "sourceId": 8089,
     "sourceType": "competition"
    },
    {
     "datasetId": 181273,
     "sourceId": 407317,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "data-sci",
   "language": "python",
   "name": "data-sci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
